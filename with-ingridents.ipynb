{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "mgvHA-wD_4Ij"
      },
      "outputs": [],
      "source": [
        "import requests"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup"
      ],
      "metadata": {
        "id": "Y56TRCsmAa2g"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "j0PdPhrQADVS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GHrDG-FEALbY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "books = []\n",
        "\n",
        "def extract_ingredients(product_url):\n",
        "    response = requests.get(product_url)\n",
        "    if response.status_code == 200:\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "        ingredients_element = soup.find('div', class_='athenaProductPageSynopsisContent')\n",
        "        ingredients = ingredients_element.text.strip() if ingredients_element else \"\"\n",
        "        return ingredients\n",
        "    else:\n",
        "        print(f\"Failed to retrieve product page. Status code: {response.status_code}\")\n",
        "        return \"\"\n",
        "\n",
        "for i in range(1, 23):\n",
        "    url = f\"https://www.lookfantastic.com/health-beauty/new/trending.list?pageNumber={i}\"\n",
        "\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        # Extract data from the current page\n",
        "        product_blocks = soup.select('.productBlock')\n",
        "        for block in product_blocks:\n",
        "            # Extracting product information\n",
        "            product_name = block.select_one('.productBlock_productName').text.strip()\n",
        "            product_brand = block.select_one('[data-product-brand]').get('data-product-brand')\n",
        "            product_price = block.select_one('[data-product-price]').get('data-product-price')\n",
        "\n",
        "            # Extracting product URL\n",
        "            product_url = block.select_one('.productBlock_link').get('href')\n",
        "            full_product_url = f\"https://www.lookfantastic.com{product_url}\"\n",
        "\n",
        "            # Extracting ingredients using the product URL\n",
        "            ingredients = extract_ingredients(full_product_url)\n",
        "\n",
        "            # Append data to books list\n",
        "            books.append([product_name, product_brand, product_price, ingredients])\n",
        "\n",
        "    except requests.RequestException as e:\n",
        "        print(f\"Failed to retrieve page {i}. Exception: {e}\")\n"
      ],
      "metadata": {
        "id": "gyg1yMbPBy7m"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(books, columns=['Product_name','Product_brand','Product_price','ingredients'])"
      ],
      "metadata": {
        "id": "YoIDFW9aHS2K"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('shop.csv')"
      ],
      "metadata": {
        "id": "0uszGJnVH-MM"
      },
      "execution_count": 7,
      "outputs": []
    }
  ]
}
